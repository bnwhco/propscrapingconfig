# Real Estate Property Scraper & Mapper - Browser Plugin
── amplify/
│   ├── auth/
│   │   └── resource.ts
│   ├── data/
│   │   └── resource.ts
│   ├── functions/
│   │   └── scrapingFunction/
│   │       ├── resource.ts
│   │       ├── handler.ts
│   │       ├── package.json
│   │       └── tsconfig.json
│   └── backend.ts
│   └── outputs.json         # Generated by Amplify CLI
├── public/
│   ├── manifest.json
│   ├── icons/
│   │   └── icon128.png      # Add other sizes (16, 48)
│   ├── sidepanel.html
│   └── popup.html           # Optional simple popup
├── src/
│   ├── main.tsx             # Entry for Side Panel UI
│   ├── App.tsx              # Main React App component
│   ├── components/
│   │   ├── PropertyList.tsx
│   │   ├── DataMappingTable.tsx
│   │   ├── UrlInput.tsx
│   │   └── LoadingSpinner.tsx
│   ├── hooks/
│   │   ├── useScraper.ts
│   │   ├── useConfig.ts
│   │   └── useAuthStatus.ts # Simple hook for auth state
│   ├── types/
│   │   └── index.ts
│   ├── background.ts        # Background Service Worker
│   ├── client.ts            # Generated by Amplify CLI
│   ├── amplifyconfiguration.json # Generated by Amplify CLI
│   └── index.css            # Basic styling
├── package.json
├── tsconfig.json
├── tsconfig.node.json
├── vite.config.ts
└── README.md

This browser plugin (for Chrome & Edge) allows users to scrape property listing data from specified real estate websites (e.g., realestate.com.au, domain.com.au), view the scraped fields, map them to desired field names, and save this mapping configuration system-wide.

Built with:
*   React (TypeScript) + Vite
*   AWS Amplify Gen2 (v6+)
    *   Cognito (Email Authentication)
    *   DynamoDB (via Amplify Data for storing domain configs)
    *   Lambda (for Playwright/Cheerio web scraping)
    *   API Gateway (HTTP API trigger for Lambda)
*   Playwright & Cheerio (Web Scraping)
*   Manifest V3 (Browser Extension)

## Features

*   **Authentication:** Users must sign up/sign in with their email.
*   **URL Scraping:** Enter a property list URL (e.g., search results) or a detail URL.
*   **Data Display:** Shows scraped fields in a table on the right side panel.
*   **Field Mapping:** Allows users to enter desired field names corresponding to scraped fields.
*   **Configuration Saving:** Saves the field mapping configuration per domain (system-wide) to DynamoDB via Amplify Data.
*   **Split Screen UI:** Displays property list info (if applicable) on the left and the scraping/mapping table on the right within the browser's side panel.

## Prerequisites

*   Node.js (v18 or later recommended)
*   npm or yarn
*   AWS Account
*   Install Amplify CLI Gen2: `npm install -g @aws-amplify/cli@beta` (or use `npx @aws-amplify/cli@beta`)

## Setup & Local Development (Sandbox)

1.  **Clone the Repository:**
    ```bash
    git clone <your-repo-url>
    cd your-property-scraper-plugin
    ```

2.  **Install Dependencies:**
    ```bash
    npm install
    # or
    yarn install
    ```

3.  **Initialize Amplify Sandbox:**
    Start the local Amplify sandbox environment. This simulates the backend resources (Auth, Data, Function) locally. It will prompt you to log in to your AWS account initially to get temporary credentials.
    ```bash
    npx amplify sandbox
    ```
    *   Keep this process running in a separate terminal.
    *   It will generate `amplifyconfiguration.json` and `amplify/outputs.json` locally.
    *   The first run might take time as it sets up local containers/services.
    *   The Lambda function will run locally (requires Docker Desktop or similar). Note that `playwright-aws-lambda` might have issues running locally; you might need to adjust the Lambda handler during local testing to use standard `playwright` if you have browsers installed locally, or accept limitations.

4.  **Generate Type-Safe Client:** (Often done automatically by `sandbox`, but run manually if `src/client.ts` is missing or out of date)
    ```bash
    npx amplify generate client
    ```

5.  **Build the Extension for Development:**
    Run the Vite development server. `vite-plugin-web-extension` will create a `dist/` directory suitable for loading as an unpacked extension.
    ```bash
    npm run dev
    ```
    *   Keep this running. It will watch for file changes and rebuild.

6.  **Load the Unpacked Extension:**
    *   **Chrome:** Go to `chrome://extensions/`, enable "Developer mode", click "Load unpacked", and select the `dist` folder inside your project directory.
    *   **Edge:** Go to `edge://extensions/`, enable "Developer mode", click "Load unpacked", and select the `dist` folder.

7.  **Test:**
    *   Click the extension icon in your browser toolbar. It should open the simple popup.
    *   Click the "Open Scraper" button in the popup to open the side panel.
    *   You should be prompted to Sign Up / Sign In via the Amplify Authenticator UI.
    *   Navigate to a supported real estate site (e.g., a realestate.com.au search results page).
    *   The URL might auto-populate. Click "Scrape URL".
    *   View the scraped data and map fields in the right panel.
    *   Save the config.
    *   Check the Sandbox logs (in the terminal where `npx amplify sandbox` is running) for backend activity and errors (especially Lambda logs). Use browser DevTools for frontend debugging.

## Deployment to AWS

1.  **Deploy Backend Resources:**
    This command will provision the actual AWS resources (Cognito, DynamoDB, Lambda, API Gateway) defined in your `amplify/` directory in your AWS account.
    ```bash
    npx amplify deploy
    ```
    *   This will create a CloudFormation stack. Follow the prompts.
    *   After deployment, it will update `amplify/outputs.json` with the *real* resource details (like the API Gateway endpoint URL).

2.  **Generate Production Frontend Config:**
    Update `amplifyconfiguration.json` with the outputs from the deployed backend.
    ```bash
    npx amplify generate config --environment <your-env-name> # Usually 'prod' or omitted if default
    # or simply rely on the update from `amplify deploy`
    ```

3.  **Build the Extension for Production:**
    Create an optimized production build.
    ```bash
    npm run build
    ```
    This will generate the final extension files in the `dist/` directory.

4.  **Update Manifest Host Permissions:**
    *   **CRITICAL:** Open `public/manifest.json`.
    *   Find the `host_permissions` section.
    *   Replace the broad `"*.amazonaws.com/*"` permission with the **specific API Gateway endpoint URL** for your deployed `scrapingFunction`. You can find this URL in `amplify/outputs.json` (look for `ScraperApiEndpoint` or similar under `custom`). It will look something like `https://<api-id>.execute-api.<region>.amazonaws.com/*`.
    *   **Re-run `npm run build`** to include the updated manifest in the final `dist` folder.

5.  **Package and Distribute:**
    *   Zip the contents of the `dist/` directory.
    *   Upload the zip file to the Chrome Web Store or Edge Add-ons portal for distribution.

## Important Considerations & Future Improvements

*   **Scraper Selectors:** The CSS selectors in `amplify/functions/scrapingFunction/handler.ts` are **examples** and **will break** when the target websites change their structure. They need constant monitoring and updating. Use more robust selectors (e.g., based on `data-testid` attributes if available) where possible.
*   **Lambda Resources:** Playwright is resource-intensive. Monitor Lambda execution time and memory usage in CloudWatch. Increase `memoryMB` and `timeoutSeconds` in `amplify/functions/scrapingFunction/resource.ts` if necessary.
*   **Error Handling:** Implement more robust error handling in both the frontend hooks and the Lambda function. Provide clearer feedback to the user.
*   **CAPTCHAs & Blocking:** Scraping sites like the Valuer General or heavily protected portals is extremely difficult due to CAPTCHAs and anti-bot measures. Fully automated solutions might violate Terms of Service. Consider using CAPTCHA solving services (adds cost/complexity) or limiting scope. Implement delays and realistic user agents in Playwright to reduce blocking risk.
*   **Configuration Security:** The current `DomainConfig` allows any authenticated user to modify system-wide configurations. In a production scenario, restrict create/update/delete permissions to an 'admin' user group using Amplify Auth rules (`allow.group('admin').to(['create', 'update', 'delete'])` in `amplify/data/resource.ts`).
*   **Detail URL Extraction:** The logic in `PropertyList.tsx` to get the detail URL is a placeholder. The Lambda scraper should ideally extract the specific detail page URL for each list item and return it as a dedicated field (e.g., `detail_url_list`).
*   **Change Detection:** Implement functionality to store scraped data per property and compare it over time to detect changes (requires expanding the data model).
*   **CORS:** Ensure the Lambda function always returns the correct `Access-Control-Allow-Origin` header. Restrict the `*` to your specific extension ID in production (`chrome-extension://<your-extension-id>`). This requires knowing your extension ID after publishing.